{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6c667d4-0bb8-4570-9fc3-c94c3efcd6e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- ProductID: integer (nullable = true)\n |-- Date: date (nullable = true)\n |-- Zip: string (nullable = true)\n |-- Units: integer (nullable = true)\n |-- Revenue: double (nullable = true)\n |-- Country: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"s8a-dataframes-api\").getOrCreate()\n",
    "# Lectura de CSV con el ; como separador de columnas y con encabezado\n",
    "df = spark.read.option(\"sep\",\";\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"/FileStore/dataframes-api/dataset/pdi_sales_small.csv\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b7299f8-8832-49be-8da9-d11faf731be9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Agregaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92d037bf-259b-4874-86c3-5169170650ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Una vez tenemos un DataFrame, podemos realizar analítica de datos sobre el dataset entero, o sobre una o más columnas y aplicar una función de agregación que permita sumar, contar o calcular la media de cualquier grupo, entre otras opciones. Para ello, PySpark ofrece un amplio [conjunto de funciones](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#functions). En nuestro caso, vamos a realizar algunos ejemplos para practicar con las funciones más empleadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c9abc2b4-d03b-4842-8549-0363f681233e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Contando"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "856f4bb2-e560-4b9c-a919-f37b34126292",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**[count](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.count.html)** : Devuelve la cantidad de elementos no nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3cd21a6-29a7-4e90-affb-51981932c21d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n|count(Country)|\n+--------------+\n|        120239|\n+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "df.select(count(\"Country\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4fab414-7f7c-46e2-8944-c9df6dba2851",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**[count_distinct/countDistinct](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.count_distinct.html):** Devuelve la cantidad de elementos no nulos diferentes:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc77c874-38e4-4db2-a524-94c9789acdbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-------------------+\n|count(DISTINCT Country)|count(DISTINCT Zip)|\n+-----------------------+-------------------+\n|                      5|               2585|\n+-----------------------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count_distinct\n",
    "df.select(count_distinct(\"Country\"), count_distinct(\"Zip\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "092067d6-c0ac-4d9f-9709-9328cd49e456",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**[approx_count_distinct / approxCountDistinct:](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.approx_count_distinct.html)** Devuelve aproximadamente la cantidad de elementos no nulos diferentes (puede recibir un segundo parámetro la máximo desviación estándar admitida). Este método es mucho más rápido que contar exactamente el número de resultado, y para datasets muy grandes, en ocasiones puede ser útil:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f883572b-802d-4688-a92b-11ae088eaafa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+--------------------------+\n|approx_count_distinct(Country)|approx_count_distinct(Zip)|\n+------------------------------+--------------------------+\n|                             5|                      2737|\n+------------------------------+--------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import approx_count_distinct\n",
    "df.select(approx_count_distinct(\"Country\"), approx_count_distinct(\"Zip\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f40283de-50a9-4521-8637-c0f54bad6bcf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Calculando"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d09b2b8a-57e8-42c4-9ec0-b5e2e22db093",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**[min](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.min.html) y [max](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.max.html)**: permiten obtener el menor y el mayor valor respectivamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bd9f5e7-55cf-4300-83d2-73ab2960f450",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n|min(Units)|max(Units)|\n+----------+----------+\n|         1|        77|\n+----------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import min, max\n",
    "df.select(min(\"Units\"), max(\"Units\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "354779ee-7ab4-4257-9044-1b111a20db9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "[sum](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.sum.html) permite sumar todos los valores de una columna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "135293ca-4f80-4e18-b4c4-faa7bd3ccb0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+\n|sum(Units)|       sum(Revenue)|\n+----------+-------------------+\n|    125728|5.010727499998837E7|\n+----------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum\n",
    "df.select(sum(\"Units\"), sum(\"Revenue\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c9dc0a8d-b62d-4f10-9104-67cc313f8b86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**[sum_distinct / sumDistinct](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.sum_distinct.html)**: suma los valores diferentes de una columna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab6f8547-78b9-442d-9ce5-2a225dbf8f09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------------------+\n|sum(DISTINCT Units)|sum(DISTINCT Revenue)|\n+-------------------+---------------------+\n|                308|    1189127.099999999|\n+-------------------+---------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum_distinct\n",
    "df.select(sum_distinct(\"Units\"), sum_distinct(\"Revenue\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23c81129-19f4-4d4b-936a-40467f789297",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Asimetría, varianza y desviación estándar**: Si nos interesa obtener información estadística sobre los datos, también disponemos de las funciones `skewness`, `kurtosis`, `variance`, `var_pop`, `stddev` y `stddev_pop`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ecacf2e2-b1df-446b-8d81-0df105959a45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> Actividad: Desarrolla ejemplos simples de como calcular con Pyspark las funciones `skewness`, `kurtosis`, `variance`, `var_pop`, `stddev` y `stddev_pop`. Explicar como se interpretan cada una de ellas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "76c83cad-b0b0-43b6-96bf-3097268c8b5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "`Skewness` (Sesgo)\n",
    "El skewness nos indica la asimetría de los datos. Usaremos la columna Units como ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db3d0749-19ad-45f2-b26e-1f74af72b74b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n|         Skewness|\n+-----------------+\n|82.93416153957504|\n+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import skewness\n",
    "\n",
    "# Calcular skewness de la columna 'Units'\n",
    "df.select(skewness(\"Units\").alias(\"Skewness\")).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8132ac4-5252-43b6-bc87-49f57e4b3ec9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "`Kurtosis`\n",
    "La kurtosis mide qué tan altos y estrechos son los picos en los datos. Vamos a calcularlo para Revenue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d9a79dd-2f2e-4cf9-9c67-bd9edb411b9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n|         Kurtosis|\n+-----------------+\n|1863.073715098713|\n+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import kurtosis\n",
    "\n",
    "# Calcular kurtosis de la columna 'Revenue'\n",
    "df.select(kurtosis(\"Revenue\").alias(\"Kurtosis\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3745776d-f28f-4423-8d72-f78a26a15b05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "`Variance` (Varianza)\n",
    "La varianza nos dice cuánto se dispersan los datos respecto a su media. Vamos a calcular la varianza de Units:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a44f870-e288-47c6-b52a-17bcbb96a198",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n|           Variance|\n+-------------------+\n|0.15890503050126042|\n+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import variance\n",
    "\n",
    "# Calcular la varianza de la columna 'Units'\n",
    "df.select(variance(\"Units\").alias(\"Variance\")).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fea0b043-2369-4f1a-9d98-966e7d644d6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Varianza Poblacional (`var_pop`)\n",
    "La varianza poblacional se calcula considerando todo el conjunto de datos como población. Vamos a calcularlo para Revenue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ced47fd9-68aa-4147-9c47-fe0d070f8d01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n|           Var_Pop|\n+------------------+\n|123345.05745186073|\n+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import var_pop\n",
    "\n",
    "# Calcular varianza poblacional de la columna 'Revenue'\n",
    "df.select(var_pop(\"Revenue\").alias(\"Var_Pop\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "077cc66a-7000-4b9d-a868-580b39e54fc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Desviación Estándar (`stddev`)\n",
    "La desviación estándar nos muestra cuánto se dispersan los datos. Usaremos Units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2dde1898-c44f-47b5-a38b-e83b7d581e14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n|            Stddev|\n+------------------+\n|0.3986289383640636|\n+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import stddev\n",
    "\n",
    "# Calcular la desviación estándar de la columna 'Units'\n",
    "df.select(stddev(\"Units\").alias(\"Stddev\")).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "352c2d4f-c116-404a-a078-00ba3236760a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Desviación Estándar Poblacional (`stddev_pop`)\n",
    "La desviación estándar poblacional se utiliza cuando tienes la población completa de datos. Vamos a calcularla para Revenue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a0d729d-443e-4ae9-a220-770b97b8d8a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n|        Stddev_Pop|\n+------------------+\n|351.20515009302005|\n+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import stddev_pop\n",
    "\n",
    "# Calcular desviación estándar poblacional de la columna 'Revenue'\n",
    "df.select(stddev_pop(\"Revenue\").alias(\"Stddev_Pop\")).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5ea98c4-1501-44a2-9a04-a7a22827a539",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Agrupando  \n",
    "\n",
    "Si agrupamos varias columnas de tipo categóricas (con una cardinalidad baja), podemos realizar cálculos sobre el resto de columnas.  \n",
    "\n",
    "Sobre un DataFrame, podemos agrupar los datos por la columna que queramos utilizando el método[ groupBy](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.groupBy.html), el cual nos devuelve un [GroupedData](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.GroupedData.html#pyspark.sql.GroupedData), sobre el que posteriormente realizar operaciones como `avg(cols)`, `count()`, `mean(cols)`, `min(cols)`, `max(cols)` o `sum(cols)`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd074476-fd84-4a95-9132-1449f8b15d55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**count**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "217e67a5-f857-489b-88aa-59a02fefddc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n|Country|count|\n+-------+-----+\n|Germany|30059|\n|France |30059|\n|Canada |30060|\n|Mexico |30060|\n| France|    1|\n+-------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum\n",
    "df.groupBy(\"Country\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f81da1b1-f5f2-4238-a741-4463ad6ef947",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**sum**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cfea4ca-4c39-4fb3-b230-5b3c87e4a4b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n|Country|        sum(Revenue)|\n+-------+--------------------+\n|Germany|  1.49821199999994E7|\n|France |1.2086961900000686E7|\n|Canada |1.1642614200001836E7|\n|Mexico |1.1394598700001087E7|\n| France|               980.2|\n+-------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Country\").sum(\"Revenue\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a96b2c33-ebdb-488b-bc95-b57563c3a336",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Si necesitamos realizar más de un agregación sobre el mismo grupo, mediante [agg](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.GroupedData.agg.html) podemos indicar una o más expresiones de columnas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd6ba3e9-f0f2-402a-bb4c-b2c328e1c9f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------+\n|Country|        sum(Revenue)|count(Revenue)|\n+-------+--------------------+--------------+\n|Germany|  1.49821199999994E7|         30059|\n|France |1.2086961900000686E7|         30059|\n|Canada |1.1642614200001836E7|         30060|\n|Mexico |1.1394598700001087E7|         30060|\n| France|               980.2|             1|\n+-------+--------------------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum, count\n",
    "df.groupBy(\"Country\").agg(sum(\"Revenue\"), count(\"Revenue\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9d2a844-b170-4eb7-a855-dcb063cedd5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "También podemos indicar los elementos a calcular mediante un diccionario donde las claves son los campos y los valores la función a calcular:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "227c38d9-a10e-4c3c-9030-ad2a5b79cdcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------------------+\n|Country|count(Zip)|      avg(Revenue)|\n+-------+----------+------------------+\n|Germany|     30059| 498.4237665923484|\n|France |     30059| 402.1079177617581|\n|Canada |     30060|387.31251497012096|\n|Mexico |     30060| 379.0618330007015|\n| France|         1|             980.2|\n+-------+----------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Country\").agg({\"Zip\":\"count\", \"Revenue\":\"avg\"}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4574afbf-6a5a-48a7-920a-f02d82e51d40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Agrupando colecciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38d42086-103a-4186-8f0e-5c90c2016266",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "En ocasiones necesitamos agrupar en una colección todos los valores para un grupo en particular. Para ello, podemos usar [collect_list](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.collect_list.html) (con repetidos) o [collect_set](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.collect_set.html) (sin repeticiones):  \n",
    "\n",
    "Por ejemplo, para cada país, vamos a recuperar un listado con los códigos postales de aquellos pedidos que hayan superado las 5 unidades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "683459dd-5c7c-46dc-bb76-25fa24f0210b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n|Country|   collect_list(Zip)|    collect_set(Zip)|\n+-------+--------------------+--------------------+\n|Germany|[22397          ,...|[22111          ,...|\n|France |[75213 CEDEX 16 ,...|[75391 CEDEX 08 ,...|\n|Mexico |[7100           ,...|[10300          ,...|\n|Canada |[T2X            ,...|[T6V            ,...|\n+-------+--------------------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import collect_list, collect_set\n",
    "df.where(\"Units > 5\").groupBy(\"Country\").agg(collect_list(\"Zip\"), collect_set(\"Zip\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c184ad2-84c1-4546-9342-7acf0a9b4ef3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Tablas pivote  \n",
    "Las tablas pivote permiten obtener un resumen de los datos a partir de columnas categóricas sobre la que realizar cálculos, tal como se hace en las hojas de cálculo con las tablas dinámicas.  \n",
    "\n",
    "Por ejemplo, vamos a obtener la cantidad recaudada por las ventas de cada año por cada país:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d553ed1-d207-46b0-8b3d-8e3e7405c1e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+------+------------------+-----------------+------------------+\n|Year|           Canada |France|           France |          Germany|           Mexico |\n+----+------------------+------+------------------+-----------------+------------------+\n|2003| 2360085.999999949|  null|1105230.9000000039|1407119.999999999|1049457.4999999995|\n|2004| 1539140.499999946|  null|              null|             null|              null|\n|2001| 2193437.799999908|  null|              null|             null|233419.20000000004|\n|2000|1806678.3999999042|  null|1108846.8999999764|4510606.799999929| 4240448.399999948|\n|1999|1382756.6999999755|  null| 7594921.200000447|5928459.100000297|3419368.2000001906|\n|2002|2360514.7999998718| 980.2| 2277962.899999955|3135934.099999969| 2451905.399999923|\n+----+------------------+------+------------------+-----------------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year\n",
    "\n",
    "df.groupBy(year(\"Date\").alias(\"Year\")).pivot(\"Country\").sum(\"Revenue\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db2139ca-0a92-4139-a41d-de7eddc3293a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "También podemos hacer más de un cálculo sobre la tabla pivote:  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f52a612-4f22-4e23-bc38-c310397a0569",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+----------------+------------+---------------+------------------+----------------+-----------------+----------------+------------------+----------------+\n|year(Date)|     Canada _total|Canada _cantidad|France_total|France_cantidad|     France _total|France _cantidad|    Germany_total|Germany_cantidad|     Mexico _total|Mexico _cantidad|\n+----------+------------------+----------------+------------+---------------+------------------+----------------+-----------------+----------------+------------------+----------------+\n|      2003| 2360085.999999949|            6375|        null|           null|1105230.9000000039|            2794|1407119.999999999|            3099|1049457.4999999995|            2510|\n|      2004| 1539140.499999946|            3636|        null|           null|              null|            null|             null|            null|              null|            null|\n|      2001| 2193437.799999908|            5976|        null|           null|              null|            null|             null|            null|233419.20000000004|             583|\n|      2000|1806678.3999999042|            5049|        null|           null|1108846.8999999764|            2456|4510606.799999929|            9738| 4240448.399999948|           11935|\n|      1999|1382756.6999999755|            3964|        null|           null| 7594921.200000447|           20432|5928459.100000297|           12266|3419368.2000001906|            9895|\n|      2002|2360514.7999998718|            6148|       980.2|              1| 2277962.899999955|            6056|3135934.099999969|            6643| 2451905.399999923|            6172|\n+----------+------------------+----------------+------------+---------------+------------------+----------------+-----------------+----------------+------------------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(year(\"Date\")).pivot(\"Country\").agg(sum(\"Revenue\").alias(\"total\"), sum(\"Units\").alias(\"cantidad\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b4e7ff58-0282-43ba-9d93-532ad18138f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa881906-a5ba-4b98-addf-167ba7dc029a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Hasta ahora todo la analítica la hemos realizado sobre un único DataFrame. Aunque si seguimos un proceso ELT es probable que tengamos todos los datos en un único lugar, en ocasiones necesitamos cruzar la información de dos datasets.\n",
    "\n",
    "Si nos basamos en el planteamiento de una base de datos relacional, para unir dos DataFrames necesitamos unir la clave ajena de uno con la clave primaria del otro.\n",
    "\n",
    "Para estos ejemplos, vamos a cambiar de datasets y utilizar datos de vuelos de avión que han tenido algún tipo de retraso ([departure_delays.csv](https://tajamar365.sharepoint.com/:x:/s/3405-MasterIA2024-2025/EVXFsnm7tWdIv7hohU6UsRgBIdV_ghMxvtUxSyduUcxYow?e=n85sNv)) y otro con los códigos de los aeropuertos ([airport-codes-na.tsv](https://tajamar365.sharepoint.com/:u:/s/3405-MasterIA2024-2025/EePe905sgTZOnSMvFE9DpV4BLHICLNcb9VTIYEU7svCOcw?e=AxFwQE))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "722c95c3-335e-431c-abfb-b6c8d3b5821b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Vuelos con retraso**  \n",
    "Fichero CSV con la coma como separador de campos.   \n",
    "```<csv> \n",
    "date,delay,distance,origin,destination\n",
    "01011245,6,602,ABE,ATL\n",
    "01020600,-8,369,ABE,DTW\n",
    "01021245,-2,602,ABE,ATL\n",
    "01020605,-4,602,ABE,ATL\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b1f8d10-c9cc-4f4e-8a85-c7e83663012d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Códigos de aeropuertos**  \n",
    "\n",
    "Fichero TSV con el tabulador como separador campos, donde el campo `IATA` es la clave de cada aeropuerto.  \n",
    "```<tsv>\n",
    "City State Country IATA\n",
    "Abbotsford BC Canada YXX\n",
    "Aberdeen SD USA ABR\n",
    "Abilene TX USA ABI\n",
    "Akron OH USA CAK\n",
    "Alamosa CO USA ALS\n",
    "Albany GA USA ABY\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf2acbae-2358-4a91-bb48-bbd397ec9185",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Así pues, lo primero que vamos a hacer es cargar ambos DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40da77b3-6cfa-473b-93ca-cd91e38b2edf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- City: string (nullable = true)\n |-- State: string (nullable = true)\n |-- Country: string (nullable = true)\n |-- IATA: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"s8a-dataframes-joins\").getOrCreate()\n",
    "\n",
    "df_vuelos = spark.read.option(\"sep\",\",\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"/FileStore/dataframes-api/dataset/departure_delays.csv\")\n",
    "# df_vuelos.printSchema()\n",
    "# df_vuelos.count()   # 1391578\n",
    "df_aeropuertos = spark.read.option(\"sep\",\"\\t\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"/FileStore/dataframes-api/dataset/airport_codes_na.tsv\")\n",
    "df_aeropuertos.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "85b2003e-3f93-40ff-99bd-959c522989be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Mediante SQL  \n",
    "Si queremos hacer un join mediante SQL, sólo tenemos que emplear la misma sintaxis que con cualquier sistema relacional, de manera que primero crearemos las vistas temporales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "630fd065-9772-4cd9-94cb-2aa732dc42c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_vuelos.createOrReplaceTempView(\"vuelos\")\n",
    "df_aeropuertos.createOrReplaceTempView(\"aeropuertos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9597f85a-3d7f-49e6-881e-89f3a59232a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Y a continuación realizamos la consulta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0564911e-2da6-4bd9-9ff6-ba2bcc6e0752",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n|origin|     city|\n+------+---------+\n|   ABE|Allentown|\n|   ABE|Allentown|\n|   ABE|Allentown|\n+------+---------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_join = spark.sql(\"select v.origin, a.city from vuelos v join aeropuertos a on v.origin == a.IATA\")\n",
    "df_join.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f8411f54-c0de-42ef-a84e-1e8a44af435d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Si quisiéramos obtener el nombre de los dos aeropuertos, necesitamos realizar dos veces el join:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7fdc502a-2301-473d-a6d8-280310f95936",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+--------+------+-----------+----------+---------------+\n|   date|delay|distance|origin|destination|originCity|destinationCity|\n+-------+-----+--------+------+-----------+----------+---------------+\n|1011245|    6|     602|   ABE|        ATL| Allentown|        Atlanta|\n|1020600|   -8|     369|   ABE|        DTW| Allentown|        Detroit|\n|1021245|   -2|     602|   ABE|        ATL| Allentown|        Atlanta|\n+-------+-----+--------+------+-----------+----------+---------------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_join = spark.sql(\"select v.*, a.City as originCity, b.City as destinationCity from vuelos v JOIN aeropuertos a on v.origin == a.IATA join aeropuertos b on v.destination = b.IATA\")\n",
    "df_join.show(3)\n",
    "\n",
    "# +-------+-----+--------+------+-----------+----------+---------------+\n",
    "# |   date|delay|distance|origin|destination|originCity|destinationCity|\n",
    "# +-------+-----+--------+------+-----------+----------+---------------+\n",
    "# |1011245|    6|     602|   ABE|        ATL| Allentown|        Atlanta|\n",
    "# |1020600|   -8|     369|   ABE|        DTW| Allentown|        Detroit|\n",
    "# |1021245|   -2|     602|   ABE|        ATL| Allentown|        Atlanta|\n",
    "# +-------+-----+--------+------+-----------+----------+---------------+\n",
    "# only showing top 3 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c47df65-8a29-4f7d-9972-0d972aed6e31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Si existiera algún vuelo cuyos códigos de aeropuerto no tuviéramos disponible en el dataset de los códigos de aeropuertos, no nos aparecería. Por tanto, sería más conveniente realizar un left join:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdbe6e4c-6ebe-442a-89c1-afed37d1cc5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+--------+------+-----------+----------+---------------+\n|   date|delay|distance|origin|destination|originCity|destinationCity|\n+-------+-----+--------+------+-----------+----------+---------------+\n|1011245|    6|     602|   ABE|        ATL| Allentown|        Atlanta|\n|1020600|   -8|     369|   ABE|        DTW| Allentown|        Detroit|\n|1021245|   -2|     602|   ABE|        ATL| Allentown|        Atlanta|\n+-------+-----+--------+------+-----------+----------+---------------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_left_join = spark.sql(\"select v.*, a.City as originCity, b.City as destinationCity from vuelos v LEFT JOIN aeropuertos a on v.origin == a.IATA LEFT JOIN aeropuertos b on v.destination = b.IATA\")\n",
    "df_left_join.show(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c155ca9-aeca-499d-b5dd-7cc6d8529d1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[28]: 1391578"
     ]
    }
   ],
   "source": [
    "df_left_join.count()    # 1391578"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c3e04d0-936c-4e37-8db1-4fce17d723c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> **Todo tipo de joins**  \n",
    " Además de los casos vistos, podemos realizar otros tipos de joins como `cross`, `semi`, `full`, `outer`, etc... Más información en la [documentación oficial](https://spark.apache.org/docs/latest/sql-ref-syntax-qry-select-join.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea7920aa-67e1-44f6-8437-747a5aca722f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Un caso particular que conviene conocer es el left anti join. Este tipo de join permite obtener aquellos registros de la izquierda que no aparecen en la parte derecha, de manera que si seguimos con el ejemplo, podemos recuperar aquellos vuelos cuyos aeropuertos no tenemos en el dataset con los códigos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92b5eaa3-5971-445a-84cd-4065ea331859",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[29]: 14416"
     ]
    }
   ],
   "source": [
    "df_left_anti_join = spark.sql(\"select * from vuelos v LEFT ANTI JOIN aeropuertos a ON v.origin == a.IATA \")\n",
    "df_left_anti_join.count()   # 14416"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b04fe7e3-24f2-40ce-82ba-ab99816b66f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Mediante Python  \n",
    "\n",
    "Si no queremos utilizar SQL o ya tenemos fragmentos de código que interactúan con el DataFrame API, podemos utilizar el método `join`. Este método une dos DataFrames, indicando la expresión de unión y opcionalmente el tipo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2ffde4f-6555-4e54-a9e4-f611c7c1d776",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "exprJoin1 = df_vuelos.origin == df_aeropuertos.IATA\n",
    "df_joinp1 = df_vuelos.join(df_aeropuertos, exprJoin1, \"inner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f03600d-bffd-4358-96f2-4ca42f852127",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[31]: 1377162"
     ]
    }
   ],
   "source": [
    "df_joinp1.count()    # 1377162"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f49b075-3e00-4cd6-ac53-d0f95392ba21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> **Forma corta**. Si las columnas que unen los DataFrames tienen el mismo nombre, podemos simplificar el código indicando únicamente su nombre:  \n",
    "`df1.join(df2, \"user_id\")`  \n",
    "Además, si queremos hacer un inner join, podemos no indicarlo ya que es el tipo por defecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f24dbcf2-e14d-4100-9f78-876983b2db61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "En vez de pasarle `inner`, le podemos indicar el tipo de join: `left`, `right`, `cross`, `left_anti`, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d1a45b1-8c51-4e09-bc9d-2f232bc7f3e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[32]: 14416"
     ]
    }
   ],
   "source": [
    "expr_join1 = df_vuelos.origin == df_aeropuertos.IATA\n",
    "df_left_anti_join = df_vuelos.join(df_aeropuertos, expr_join1, \"left_anti\")\n",
    "df_left_anti_join.count()   # 14416"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2d02e1f-4829-4df2-8c89-8cac5a13939e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Finalmente, como en nuestro caso teníamos dos joins, tanto para los vuelos de origen como los de destino, necesitamos volver a unir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3d698db-38ca-4847-9f9e-6fe55b0b5ebc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[33]: 1361141"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "# le indicamos alias a los campos para eliminar ambigüedades\n",
    "expr_join2 = col(\"a.destination\") == col(\"b.IATA\")\n",
    "df_joinp2 = (df_joinp1.alias(\"a\")).join((df_aeropuertos.alias(\"b\")), expr_join2, \"inner\")\n",
    "df_joinp2.count()    # 1361141"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48346e6f-4ec8-472f-8ded-477082dd2df4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Funciones  \n",
    "Para dominar realmente Spark, hay que tener destreza en todas las funciones existentes para el tratamiento de fechas, cadenas, operaciones matemáticas, para trabajar con colecciones, etc...\n",
    "\n",
    "Además, siempre podemos crear nuestras propias funciones de usuario para ampliar el lenguaje.\n",
    "\n",
    "Aunque ya hemos utilizado algunas a lo largo de los apuntes, a continuación vamos a repasar las funciones más empleadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f85a1dd-028b-4581-bdb5-eaa68357f622",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Fechas  \n",
    "- Si necesitamos convertir de texto a fecha: [to_date](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.to_date.html), [to_timestamp](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.to_timestamp.html), [unix_timestamp](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.unix_timestamp.html)  \n",
    "- Para formatear las fechas: [date_format](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.date_format.html), [from_unixtime](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.from_unixtime.html) ([patrones de fechas](https://spark.apache.org/docs/latest/sql-ref-datetime-pattern.html))  \n",
    "- Para realizar cálculos sobre fechas: `datediff`, `months_between`, `last_day`, `date_add`, `date_sub`, `next_day`.  \n",
    "- Extraer un valor de una fecha:[ year](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.year.html), [month](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.month.html), [weekofyear](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.weekofyear.html), [dayofmonth](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.dayofmonth.html), [dayofyear](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.dayofyear.html), [hour](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.hour.html),[ minute](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.minute.html), [second](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.second.html).    \n",
    "\n",
    "Más información en la [documentación oficial](https://spark.apache.org/docs/latest/sql-ref-functions-builtin.html#date-and-timestamp-functions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "106a31fe-3006-4959-af79-d421cc2f4f56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "spark = SparkSession.builder.appName(\"s8a-dataframes-sql\").getOrCreate()\n",
    "\n",
    "df = spark.read.option(\"sep\",\";\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"/FileStore/dataframes-api/dataset/pdi_sales_small.csv\")\n",
    "# Cambiamos el tipo de dato a fecha\n",
    "df = df.withColumn(\"Date\", to_date(df.Date, \"M/d/yyy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e71a4d32-4517-43a2-a6fe-07e018865e88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-----------+-----------------+------------+-----------+-----+----+\n|      Date|Formatted_Date|Next_Sunday|Last_Day_of_Month|Day_of_Month|Day_of_Year|Month|Year|\n+----------+--------------+-----------+-----------------+------------+-----------+-----+----+\n|1999-01-15|    15-01-1999| 1999-01-17|       1999-01-31|          15|         15|    1|1999|\n|2002-06-06|    06-06-2002| 2002-06-09|       2002-06-30|           6|        157|    6|2002|\n+----------+--------------+-----------+-----------------+------------+-----------+-----+----+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import date_format, next_day, last_day, dayofmonth, dayofyear, month, year\n",
    "\n",
    "df.select(\n",
    "    \"Date\",\n",
    "    date_format(\"Date\", \"dd-MM-yyyy\").alias(\"Formatted_Date\"),\n",
    "    next_day(\"Date\", \"Sun\").alias(\"Next_Sunday\"),\n",
    "    last_day(\"Date\").alias(\"Last_Day_of_Month\"),\n",
    "    dayofmonth(\"Date\").alias(\"Day_of_Month\"),\n",
    "    dayofyear(\"Date\").alias(\"Day_of_Year\"),\n",
    "    month(\"Date\").alias(\"Month\"),\n",
    "    year(\"Date\").alias(\"Year\")\n",
    ").show(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4221c74a-6337-43fd-a973-4dcab87ea779",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Cadenas  \n",
    "Por ejemplo, tenemos las funciones para quitar espacios ([`ltrim`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.ltrim.html), [`rtrim`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.rtrim.html), [`trim`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.trim.html)) y pasar a mayúsculas/minúsculas ([`lower`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.lower.html), [`upper`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.upper.html)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52432f44-ce61-45a2-90e4-aeb88ff6ff42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+---+---------------+---------------+\n|            Zip|              l|  r|     lower(Zip)|     upper(Zip)|\n+---------------+---------------+---+---------------+---------------+\n|H1B            |H1B            |H1B|h1b            |H1B            |\n|H1B            |H1B            |H1B|h1b            |H1B            |\n|H1B            |H1B            |H1B|h1b            |H1B            |\n+---------------+---------------+---+---------------+---------------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import ltrim, rtrim, trim, lower, upper\n",
    "\n",
    "df.select(\n",
    "    \"Zip\",\n",
    "    ltrim(\"Zip\").alias(\"l\"),  # Elimina espacios en blanco a la izquierda\n",
    "    rtrim(\"Zip\").alias(\"r\"),  # Elimina espacios en blanco a la derecha\n",
    "    lower(\"Zip\").alias(\"lower(Zip)\"),  # Convierte a minúsculas\n",
    "    upper(\"Zip\").alias(\"upper(Zip)\")   # Convierte a mayúsculas\n",
    ").where(\n",
    "    trim(df.Country) == \"Canada\"  # Elimina espacios en blanco de ambos lados antes de comparar\n",
    ").show(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7bd8fca-195f-4cf1-9057-35874ca83e8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "O funciones para poner la inicial en mayúsculas ([initcap](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.initcap.html)), darle la vuelta ([reverse](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.reverse.html)), obtener su tamaño ([length](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.length.html)) o reemplazar caracteres ([translate](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.translate.html)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c5ca543-308b-4a46-8a04-870313ef1986",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+----------------+---------------+------------------+\n|Country|Initcap(Country)|Reverse(Country)|Length(Country)|Translate(Country)|\n+-------+----------------+----------------+---------------+------------------+\n|Canada |         Canada |          adanaC|              7|           Cepede |\n+-------+----------------+----------------+---------------+------------------+\nonly showing top 1 row\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import initcap, reverse, length, translate, trim\n",
    "\n",
    "df.select(\n",
    "    \"Country\",\n",
    "    initcap(\"Country\").alias(\"Initcap(Country)\"),  # Convierte a formato título (primera letra en mayúscula)\n",
    "    reverse(\"Country\").alias(\"Reverse(Country)\"),  # Invierte la cadena\n",
    "    length(\"Country\").alias(\"Length(Country)\"),    # Longitud de la cadena\n",
    "    translate(\"Country\", \"na\", \"pe\").alias(\"Translate(Country)\")  # Reemplaza 'n' con 'p' y 'a' con 'e'\n",
    ").where(\n",
    "    trim(df.Country) == \"Canada\"  # Elimina espacios en blanco antes de comparar\n",
    ").show(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aecd1462-5c28-4f6f-bc88-b6c8f7b9d190",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "También podemos trabajar con subcadenas ([substring](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.substring.html)), encontrar ocurrencias ([locate](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.locate.html)) o partir una cadena en trozos ([split](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.split.html)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cafb62ad-0740-4c9f-86b9-76ef578c0c33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+--------------------+------------------------+\n|Country|Split(Country, 'a')|Locate('a', Country)|Substring(Country, 3, 2)|\n+-------+-------------------+--------------------+------------------------+\n|Canada |       [C, n, d,  ]|                   2|                      na|\n+-------+-------------------+--------------------+------------------------+\nonly showing top 1 row\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split, locate, substring, trim\n",
    "\n",
    "df.select(\n",
    "    \"Country\",\n",
    "    split(\"Country\", \"a\").alias(\"Split(Country, 'a')\"),  # Divide la cadena por el carácter 'a'\n",
    "    locate(\"a\", \"Country\").alias(\"Locate('a', Country)\"),  # Encuentra la posición de la primera aparición de 'a'\n",
    "    substring(\"Country\", 3, 2).alias(\"Substring(Country, 3, 2)\")  # Extrae dos caracteres a partir de la posición 3\n",
    ").where(\n",
    "    trim(df.Country) == \"Canada\"  # Elimina espacios en blanco antes de comparar\n",
    ").show(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f24d5a2f-058e-414a-8802-594796501544",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Otras funciones que se suelen utilizar son [concat](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.concat.html) y [concat_ws](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.concat.html) para unir cadenas, [levenshtein](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.levenshtein.html) para calcular la distancia entre dos cadenas, [lpad](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.lpad.html) y [rpad](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.rpad.html) para completar con espacios, etc... Si necesitas trabajar con expresiones regulares puedes utilizar [regexp_extract](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.regexp_extract.html) para extraer parte de una cadena como [regexp_replace](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.regexp_replace.html) para sustituir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "042eb13c-35f8-4718-8b8e-cb9992ae2e35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Colecciones  \n",
    "Para probar las funciones que trabajan con colecciones, vamos a cambiar de dataset y trabajar con uno compartido por [Kaggle](https://www.kaggle.com/datasets/yelp-dataset/yelp-dataset) con datos de negocios de Yelp que tenemos almacenados en una versión reducida en [yelp_academic_dataset_business.json](https://tajamar365.sharepoint.com/:u:/s/3405-MasterIA2024-2025/ERoGHfFcPLhNn_YpkErPJ1oB0k9319KZG7ds-_yuklBJAg?e=ToWz1U). Los negocios tienen una propiedad denominada `categories` que contiene un array con las categorías de los mismos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a566146e-e1da-4e2e-9b53-1b483e311cbf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "```<JSON>\n",
    "{\n",
    "   \"business_id\":\"O_X3PGhk3Y5JWVi866qlJg\",\n",
    "   \"full_address\":\"1501 W Bell Rd\\nPhoenix, AZ 85023\",\n",
    "   \"hours\":{\n",
    "      \"Monday\":{\n",
    "         \"close\":\"18:00\",\n",
    "         \"open\":\"11:00\"\n",
    "      },\n",
    "      \"Tuesday\":{\n",
    "         \"close\":\"18:00\",\n",
    "         \"open\":\"11:00\"\n",
    "      },\n",
    "        ...\n",
    "   },\n",
    "   \"open\":true,\n",
    "   \"categories\":[\n",
    "      \"Active Life\",\n",
    "      \"Arts & Entertainment\",\n",
    "      \"Stadiums & Arenas\",\n",
    "      \"Horse Racing\"\n",
    "   ],\n",
    "   \"city\":\"Phoenix\",\n",
    "   ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6221d79b-7031-4f21-b534-7adfd42ae997",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "El primer paso es cargar el documento y ver el esquema inferido por Spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6eb5890b-69c7-4b5f-b55b-af2f04fe600f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- attributes: struct (nullable = true)\n |    |-- Accepts Credit Cards: boolean (nullable = true)\n |    |-- Alcohol: string (nullable = true)\n |    |-- Ambience: struct (nullable = true)\n |    |    |-- casual: boolean (nullable = true)\n |    |    |-- classy: boolean (nullable = true)\n |    |    |-- divey: boolean (nullable = true)\n |    |    |-- hipster: boolean (nullable = true)\n |    |    |-- intimate: boolean (nullable = true)\n |    |    |-- romantic: boolean (nullable = true)\n |    |    |-- touristy: boolean (nullable = true)\n |    |    |-- trendy: boolean (nullable = true)\n |    |    |-- upscale: boolean (nullable = true)\n |    |-- Attire: string (nullable = true)\n |    |-- Delivery: boolean (nullable = true)\n |    |-- Good For: struct (nullable = true)\n |    |    |-- breakfast: boolean (nullable = true)\n |    |    |-- brunch: boolean (nullable = true)\n |    |    |-- dessert: boolean (nullable = true)\n |    |    |-- dinner: boolean (nullable = true)\n |    |    |-- latenight: boolean (nullable = true)\n |    |    |-- lunch: boolean (nullable = true)\n |    |-- Good For Groups: boolean (nullable = true)\n |    |-- Good for Kids: boolean (nullable = true)\n |    |-- Has TV: boolean (nullable = true)\n |    |-- Noise Level: string (nullable = true)\n |    |-- Outdoor Seating: boolean (nullable = true)\n |    |-- Parking: struct (nullable = true)\n |    |    |-- garage: boolean (nullable = true)\n |    |    |-- lot: boolean (nullable = true)\n |    |    |-- street: boolean (nullable = true)\n |    |    |-- valet: boolean (nullable = true)\n |    |    |-- validated: boolean (nullable = true)\n |    |-- Price Range: long (nullable = true)\n |    |-- Take-out: boolean (nullable = true)\n |    |-- Takes Reservations: boolean (nullable = true)\n |    |-- Waiter Service: boolean (nullable = true)\n |    |-- Wheelchair Accessible: boolean (nullable = true)\n |    |-- Wi-Fi: string (nullable = true)\n |-- business_id: string (nullable = true)\n |-- categories: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- city: string (nullable = true)\n |-- full_address: string (nullable = true)\n |-- hours: struct (nullable = true)\n |    |-- Friday: struct (nullable = true)\n |    |    |-- close: string (nullable = true)\n |    |    |-- open: string (nullable = true)\n |    |-- Monday: struct (nullable = true)\n |    |    |-- close: string (nullable = true)\n |    |    |-- open: string (nullable = true)\n |    |-- Saturday: struct (nullable = true)\n |    |    |-- close: string (nullable = true)\n |    |    |-- open: string (nullable = true)\n |    |-- Sunday: struct (nullable = true)\n |    |    |-- close: string (nullable = true)\n |    |    |-- open: string (nullable = true)\n |    |-- Thursday: struct (nullable = true)\n |    |    |-- close: string (nullable = true)\n |    |    |-- open: string (nullable = true)\n |    |-- Tuesday: struct (nullable = true)\n |    |    |-- close: string (nullable = true)\n |    |    |-- open: string (nullable = true)\n |    |-- Wednesday: struct (nullable = true)\n |    |    |-- close: string (nullable = true)\n |    |    |-- open: string (nullable = true)\n |-- latitude: double (nullable = true)\n |-- longitude: double (nullable = true)\n |-- name: string (nullable = true)\n |-- neighborhoods: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- open: boolean (nullable = true)\n |-- review_count: long (nullable = true)\n |-- stars: double (nullable = true)\n |-- state: string (nullable = true)\n |-- type: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"s8a-dataframes-arrays\").getOrCreate()\n",
    "\n",
    "df = spark.read.option(\"inferSchema\", \"true\").option(\"multiline\",True).json(\"/FileStore/dataframes-api/dataset/yelp_academic_dataset_business.json\")\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e24d3c42-c2e8-4e7f-b15a-46cd131639f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Como se puede observar, sigue una estructura de elementos anidados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a2187ed3-47c8-4fc0-8c1a-ed181104293b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Por ejemplo, vamos a ver mediante un ejemplo las siguientes funciones:  \n",
    "- `size`: devuelve el tamaño de la colección  \n",
    "- `sort_array`: ordena la colección  \n",
    "- `array_contains`: comprueba si hay un elemento en la colección"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efd02dad-5495-4214-957e-9dab90cffe9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------+\n|hours                                                                                                           |\n+----------------------------------------------------------------------------------------------------------------+\n|{{18:00, 11:00}, {18:00, 11:00}, {18:00, 11:00}, {18:00, 11:00}, {18:00, 11:00}, {18:00, 11:00}, {18:00, 11:00}}|\n+----------------------------------------------------------------------------------------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df.select(\"hours\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0c76c32-b8d7-4d02-8a3f-53883039ab7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.filter(df[\"hours\"].isNotNull())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14d8a55c-1226-46ea-b64d-d3ea131c809c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+--------------+---------------+--------------------------------------------------------------------+------------+\n|name                     |Sunday        |totalCategories|sortedCategories                                                    |isRestaurant|\n+-------------------------+--------------+---------------+--------------------------------------------------------------------+------------+\n|Turf Paradise Race Course|{18:00, 11:00}|4              |[Active Life, Arts & Entertainment, Horse Racing, Stadiums & Arenas]|false       |\n+-------------------------+--------------+---------------+--------------------------------------------------------------------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import size, sort_array, array_contains\n",
    "\n",
    "df.select(\n",
    "    \"name\",\n",
    "    \"hours.Sunday\",\n",
    "    size(\"categories\").alias(\"totalCategories\"),  # Cuenta el número de elementos en la lista 'categories'\n",
    "    sort_array(\"categories\").alias(\"sortedCategories\"),  # Ordena los elementos de 'categories'\n",
    "    array_contains(\"categories\", \"Restaurants\").alias(\"isRestaurant\")  # Verifica si 'categories' contiene \"Restaurants\"\n",
    ").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eae13f9f-a95f-4ad6-b374-a08fdbb1a469",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Así pues, además del nombre, hemos obtenido el horario de los domingos utilizando la notación `.` para acceder a los campos anidados, la cantidad de categorías de cada comercio, un listado ordenado con sus categorías y finalmente si es un restaurante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0de59636-5ebf-41b2-a691-332e1592124f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> **Tip**  \n",
    "> Recuerda que en el apartado `Agrupando colecciones` vimos como podemos crear colecciones al realizar una agrupación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee612170-0d7f-437f-bdc4-8309a5fee7a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Otro tipo de operación que podemos realizar es desenrollar una colección mediante la función `explode` y generar una fila nueva por cada elemento de la colección:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e31fc80-ae8e-4fd7-8436-f8a5914b5dc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+--------------------+\n|name                     |col                 |\n+-------------------------+--------------------+\n|Turf Paradise Race Course|Active Life         |\n|Turf Paradise Race Course|Arts & Entertainment|\n|Turf Paradise Race Course|Stadiums & Arenas   |\n|Turf Paradise Race Course|Horse Racing        |\n+-------------------------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "\n",
    "df.select(\"name\", explode(\"categories\")).show(10, truncate=False)\n",
    "# +-------------------------+--------------------+\n",
    "# |name                     |col                 |\n",
    "# +-------------------------+--------------------+\n",
    "# |Turf Paradise Race Course|Active Life         |\n",
    "# |Turf Paradise Race Course|Arts & Entertainment|\n",
    "# |Turf Paradise Race Course|Stadiums & Arenas   |\n",
    "# |Turf Paradise Race Course|Horse Racing        |\n",
    "# |Sam's Club Members Only  |Tires               |\n",
    "# |Sam's Club Members Only  |Automotive          |\n",
    "# |Sam's Club Members Only  |Fashion             |\n",
    "# |Sam's Club Members Only  |Shopping            |\n",
    "# |Sam's Club Members Only  |Department Stores   |\n",
    "# |Forever 21               |Women's Clothing    |\n",
    "# +-------------------------+--------------------+\n",
    "# only showing top 10 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e6bc028-97ca-46a4-b6ff-343f4b36c482",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### JSON  \n",
    "\n",
    "Es común que se de el caso de que los datos que leemos desde un sistema externo estén en formato JSON pero que el proceso de ingesta lo haya realizado como si fuera una cadena de texto.\n",
    "\n",
    "Supongamos que tenemos la siguiente cadena y generados un DataFrame a partir de un RDD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1f4da7a-acbc-4154-b1a1-7098945366ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tareas = [\"\"\"{\"dia\": \"Lunes\", \"tareas\": [\"Corregir ejercicios\", \"Ir a nadar\", \"Comprar pan\"]}\"\"\"]\n",
    "# ['{\"dia\": \"Lunes\", \"tareas\": [\"Corregir ejercicios\", \"Ir a nadar\", \"Comprar pan\"]}']\n",
    "tareasRDD = spark.sparkContext.parallelize(tareas)\n",
    "tareasStrDF = tareasRDD.toDF(\"string\")\n",
    "# tareasStrDF es un DF con una columna con nombre value de tipo string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3ece677-2f5b-46c7-a403-8bd2871ee9aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- value: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "tareasStrDF.printSchema()\n",
    "# root\n",
    "#  |-- value: string (nullable = true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3d9d45c-37e4-4d76-aeb5-2f455ac071f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n|               value|\n+--------------------+\n|{\"dia\": \"Lunes\", ...|\n+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "tareasStrDF.show()\n",
    "# +--------------------+\n",
    "# |               value|\n",
    "# +--------------------+\n",
    "# |{\"dia\": \"Lunes\", ...|\n",
    "# +--------------------+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a6296fd-5d5f-43b0-ac24-dabf17527128",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Para pasarlo a JSON, necesitamos definir un esquema con la estructura del documento JSON:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "671d4a10-5cde-470b-9629-670029dc7aa9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType\n",
    "\n",
    "esquemaTareas = StructType([\n",
    "    StructField(\"dia\", StringType(), False),\n",
    "    StructField(\"tareas\", ArrayType(StringType(), False), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c8504840-859d-45f4-96b2-fb7dec7c0050",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Y a continuación ya podemos transformar el formato mediante la función [`from_json`](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.from_json.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2805dc21-cd07-4307-941c-366fd9a1ddd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- datos: struct (nullable = true)\n |    |-- dia: string (nullable = true)\n |    |-- tareas: array (nullable = true)\n |    |    |-- element: string (containsNull = true)\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import from_json\n",
    "\n",
    "todosDF = tareasStrDF.select(from_json(\"value\", esquemaTareas).alias(\"datos\"))\n",
    "todosDF.printSchema()\n",
    "# root\n",
    "#  |-- datos: struct (nullable = true)\n",
    "#  |    |-- dia: string (nullable = true)\n",
    "#  |    |-- tareas: array (nullable = true)\n",
    "#  |    |    |-- element: string (containsNull = true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b4934b1-5259-42a7-8168-391b73207489",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Y ahora ya podemos acceder a los datos (en el siguiente ejemplo empleamos la función `getItem` para acceder a un elemento de una columna, así como la notación punto mediante una expresión y los corchetes para recuperar un determinado elemento):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90d1b509-1645-426e-a629-ba8c725d6a91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------------------------------------+-------------------+\n|datos.dia|tareas                                        |tarea1             |\n+---------+----------------------------------------------+-------------------+\n|Lunes    |[Corregir ejercicios, Ir a nadar, Comprar pan]|Corregir ejercicios|\n+---------+----------------------------------------------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "todosDF.select(\n",
    "    col(\"datos\").getItem(\"dia\").alias(\"datos.dia\"),  # Extrae el campo 'dia'\n",
    "    col(\"datos\").getItem(\"tareas\").alias(\"tareas\"),  # Extrae el campo 'tareas' completo\n",
    "    col(\"datos\").getItem(\"tareas\")[0].alias(\"tarea1\")  # Accede al primer elemento de 'tareas'\n",
    ").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "492b546a-b734-4944-937d-60e6f1b021b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Para terminar, si necesitamos la operación inversa, y lo que queremos es crear una representación JSON de una columna, podemos utilizar la función [to_json](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.to_json.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5f3be16-a70f-42a5-9791-b3fde799b3a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------+\n|to_json(datos)                                                             |\n+---------------------------------------------------------------------------+\n|{\"dia\":\"Lunes\",\"tareas\":[\"Corregir ejercicios\",\"Ir a nadar\",\"Comprar pan\"]}|\n+---------------------------------------------------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_json\n",
    "\n",
    "todosDF.select(to_json(\"datos\")).show(truncate=False)\n",
    "# +---------------------------------------------------------------------------+\n",
    "# |to_json(datos)                                                             |\n",
    "# +---------------------------------------------------------------------------+\n",
    "# |{\"dia\":\"Lunes\",\"tareas\":[\"Corregir ejercicios\",\"Ir a nadar\",\"Comprar pan\"]}|\n",
    "# +---------------------------------------------------------------------------+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d9833fd-bb5f-4bea-b436-f4c9e4df530d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### UDF  \n",
    "Además de las funciones que ofrece Spark, en cualquier momento podemos crear nuestras funciones de usuario (User-Defined Functions) para ampliar la expresividad de Spark. Antes de utilizarlas, las hemos de definir y registrar.\n",
    "\n",
    "Si volvemos al dataset de ventas, teníamos la siguiente información:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d21595e5-ea3c-4fee-8a95-2624335e6413",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- ProductID: integer (nullable = true)\n |-- Date: date (nullable = true)\n |-- Zip: string (nullable = true)\n |-- Units: integer (nullable = true)\n |-- Revenue: double (nullable = true)\n |-- Country: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"s8a-dataframes-api\").getOrCreate()\n",
    "# Lectura de CSV con el ; como separador de columnas y con encabezado\n",
    "df = spark.read.option(\"sep\",\";\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"/FileStore/dataframes-api/dataset/pdi_sales_small.csv\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "679373a2-b2e4-4b1e-9041-3387758ada69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+-----+\n|ProductID|Revenue|Units|\n+---------+-------+-----+\n|      495|43194.1|   77|\n|     2091| 6347.7|   41|\n|     2091| 6240.1|   41|\n|     2091| 3652.7|   24|\n|     2091| 3560.9|   23|\n+---------+-------+-----+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "df.select(\"ProductID\", \"Revenue\", \"Units\").sort(\"Units\", ascending=False).show(5)\n",
    "# +---------+-------+-----+\n",
    "# |ProductID|Revenue|Units|\n",
    "# +---------+-------+-----+\n",
    "# |      495|43194.1|   77|\n",
    "# |     2091| 6347.7|   41|\n",
    "# |     2091| 6240.1|   41|\n",
    "# |     2091| 3652.7|   24|\n",
    "# |     2091| 3560.9|   23|\n",
    "# +---------+-------+-----+\n",
    "# only showing top 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e472f724-028b-4e2b-b2bc-7550c55744bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Vamos a crear una función para que, si vende más de una unidad, se le asigne a cada producto un bonus de un 1%. Para ello, primero definiremos la función mediante Python, y posteriormente, la registraremos mediante la función [udf](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.functions.udf.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3057eb4-b914-4b2c-95be-ed6451976853",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "def bonus(unidades, ventas):\n",
    "    if unidades == 1 :\n",
    "        return 0.0\n",
    "    else:\n",
    "        return unidades * ventas / 100\n",
    "\n",
    "udfBonus = udf(bonus, DoubleType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4264c4df-328c-4a90-8f76-0bd6c35ca787",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Así pues, si realizamos una consulta, ya podemos utilizar la función recién creada como si fuera una propia de Spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1081aa53-0b4b-4e1a-9e3d-cd19617cfa32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+-----+---------------------+\n|ProductID|Revenue|Units|bonus(Units, Revenue)|\n+---------+-------+-----+---------------------+\n|      495|43194.1|   77|   33259.456999999995|\n|     2091| 6347.7|   41|             2602.557|\n|     2091| 6240.1|   41|   2558.4410000000003|\n|     2091| 3652.7|   24|    876.6479999999999|\n|     2091| 3560.9|   23|              819.007|\n+---------+-------+-----+---------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "df.select(\"ProductID\", \"Revenue\", \"Units\", udfBonus(df.Units, df.Revenue)).sort(\"Units\", ascending=False).show(5)\n",
    "# +---------+-------+-----+---------------------+\n",
    "# |ProductID|Revenue|Units|bonus(Units, Revenue)|\n",
    "# +---------+-------+-----+---------------------+\n",
    "# |      495|43194.1|   77|   33259.456999999995|\n",
    "# |     2091| 6347.7|   41|             2602.557|\n",
    "# |     2091| 6240.1|   41|   2558.4410000000003|\n",
    "# |     2091| 3652.7|   24|    876.6479999999999|\n",
    "# |     2091| 3560.9|   23|              819.007|\n",
    "# +---------+-------+-----+---------------------+\n",
    "# only showing top 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6cd45341-3854-4f73-be5b-051b95df6ccc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Si queremos definir la función para poder utilizarla dentro de Spark SQL y obtener el mismo resultado, hemos de registrar la función mediante *spark.udf.register*, la cual recibe el nombre que le asignaremos a la función, el nombre de la función Python a invocar, y el tipo de dato que devuelve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13faa06e-50bc-486e-a9df-3e69e56bdd63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+-----+------------------+\n|ProductID|Revenue|Units|             Bonus|\n+---------+-------+-----+------------------+\n|      495|43194.1|   77|33259.456999999995|\n|     2091| 6347.7|   41|          2602.557|\n|     2091| 6240.1|   41|2558.4410000000003|\n|     2091| 3652.7|   24| 876.6479999999999|\n|     2091| 3560.9|   23|           819.007|\n+---------+-------+-----+------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Registra la función UDF\n",
    "spark.udf.register(\"udfBonus\", bonus, DoubleType())\n",
    "\n",
    "# Registra el DataFrame como una vista temporal\n",
    "df.createOrReplaceTempView(\"ventas\")\n",
    "\n",
    "# Ejecuta la consulta SQL\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT ProductID, Revenue, Units, \n",
    "           udfBonus(Units, Revenue) AS Bonus\n",
    "    FROM ventas\n",
    "    ORDER BY Units DESC\n",
    "    \"\"\"\n",
    ").show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21528961-e64a-401f-a9e2-083fb960c09f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> **UDF y Python**  \n",
    "> En un principio, se desaconseja la creación de UDF mediante Python, ya que su uso penaliza de forma significativa el rendimiento. Los ejecutores son procesos en máquinas virtuales de Java que están escritos en Java, y por ello, ejecutan código Java o Scala de forma nativa. En cambio, para Python tiene que ejecutar un proceso separado para ejecutar la UDF, lo que implica un coste extra para serializar y volver a deserializar los datos para cada fila del dataset.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5de904c2-d10d-4eda-84a5-8cb7ad38a5a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Cacheando  \n",
    "\n",
    "Un DataFrame se puede persistir/cachear en memoria conforme necesitemos (también lo podemos hacer con los RDD). Su principal propósito es cuando vamos a acceder a un DataFrame una y otra vez y no necesitamos que se vuelvan a evaluar todas las operaciones (como pueden ser los algoritmos iterativos utilizados en Machine Learning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93dc4064-61b5-47dc-901f-0ebdc940da03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> Si estás interesado en optimizar el uso de memoria al trabajar con DataFrames, [Brayan Buitrago](https://brabuitrago.medium.com/) tiene una serie de artículos sobre [Spark Performace: Cache() & Persist()](https://medium.com/iwannabedatadriven/spark-performace-cache-persist-i-c39e0c142fe5) muy interesantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "733909c4-0f3d-492c-bd39-f876dd76ae78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Cuando persistimos un dataset, cada nodo almacena sus datos particionados en memoria y/o disco y los reutiliza en otras operaciones sobre dicho dataset.  \n",
    "Para ello, se emplean los métodos [cache](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.cache.html) / [persist](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.persist.html) y [unpersist](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.unpersist.html) para cachear y liberar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9291fc8-4839-4be8-a5b0-16430ca1beb2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[75]: 120239"
     ]
    }
   ],
   "source": [
    "df.persist()\n",
    "df.count()  # forzamos la evaluación perezosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51ae40e1-7664-477a-9693-2d3f89e04ffb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------------+-----+-------+-------+\n|ProductID|      Date|            Zip|Units|Revenue|Country|\n+---------+----------+---------------+-----+-------+-------+\n|      725|1999-01-15|H1B            |    1|  115.4|Canada |\n|     2235|1999-01-15|H1B            |    2|  131.1|Canada |\n|      713|1999-01-15|H1B            |    1|  160.1|Canada |\n|      574|2002-06-05|H1B            |    1|  869.1|Canada |\n|       94|1999-02-15|H1B            |    1|  866.2|Canada |\n|      609|1999-02-15|H1B            |    1|  778.8|Canada |\n|     2064|1999-03-15|H1B            |    2|  976.4|Canada |\n|      714|1999-01-15|H1B            |    1|  160.1|Canada |\n|      826|2002-05-31|H1B            |    1|  944.9|Canada |\n|     2149|2002-06-06|H1B            |    2|  871.4|Canada |\n|      992|1999-02-15|H1B            |    1|  288.7|Canada |\n|      726|1999-01-15|M4X            |    1|  115.4|Canada |\n|      725|1999-01-15|M4X            |    1|  115.4|Canada |\n|      910|1999-03-15|M4X            |    1|  414.7|Canada |\n|      727|1999-01-15|R3T            |    1|   62.9|Canada |\n|     1426|1999-02-15|R3T            |    1|  286.0|Canada |\n|     1182|1999-01-15|R3T            |    1|  157.4|Canada |\n|      976|2002-05-31|R3T            |    1|  314.9|Canada |\n|      758|1999-01-15|R3T            |    1|   83.9|Canada |\n|     1112|1999-02-15|R3T            |    1|  116.5|Canada |\n+---------+----------+---------------+-----+-------+-------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Filtrar para ventas en Canadá\n",
    "# Limpiamos la búsqueda quitando los espacios\n",
    "ventasCanada = df.filter(trim(df[\"Country\"]) == \"Canada\")\n",
    "ventasCanada.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df826b8b-97ee-4370-a314-b730c8c25c8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ventasCanada.createOrReplaceTempView(\"ventasCanada\")\n",
    "\n",
    "spark.catalog.cacheTable(\"ventasCanada\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6938e93-cdf3-481e-aff2-62fdb7406f8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+---------------+-----+-------+-------+\n|ProductID|      Date|            Zip|Units|Revenue|Country|\n+---------+----------+---------------+-----+-------+-------+\n|      725|1999-01-15|H1B            |    1|  115.4|Canada |\n|     2235|1999-01-15|H1B            |    2|  131.1|Canada |\n|      713|1999-01-15|H1B            |    1|  160.1|Canada |\n|      574|2002-06-05|H1B            |    1|  869.1|Canada |\n|       94|1999-02-15|H1B            |    1|  866.2|Canada |\n|      609|1999-02-15|H1B            |    1|  778.8|Canada |\n|     2064|1999-03-15|H1B            |    2|  976.4|Canada |\n|      714|1999-01-15|H1B            |    1|  160.1|Canada |\n|      826|2002-05-31|H1B            |    1|  944.9|Canada |\n|     2149|2002-06-06|H1B            |    2|  871.4|Canada |\n|      992|1999-02-15|H1B            |    1|  288.7|Canada |\n|      726|1999-01-15|M4X            |    1|  115.4|Canada |\n|      725|1999-01-15|M4X            |    1|  115.4|Canada |\n|      910|1999-03-15|M4X            |    1|  414.7|Canada |\n|      727|1999-01-15|R3T            |    1|   62.9|Canada |\n|     1426|1999-02-15|R3T            |    1|  286.0|Canada |\n|     1182|1999-01-15|R3T            |    1|  157.4|Canada |\n|      976|2002-05-31|R3T            |    1|  314.9|Canada |\n|      758|1999-01-15|R3T            |    1|   83.9|Canada |\n|     1112|1999-02-15|R3T            |    1|  116.5|Canada |\n+---------+----------+---------------+-----+-------+-------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM ventasCanada\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0ca419fe-4251-44b2-8f86-c3c30595a2f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Una vez persistidos los datos, si accedemos a http://localhost:4040 (si se usa Docker + Jupyter Lab) veremos en la pestaña Storage que se ha creado la tabla, su tipo de almacenamiento y particiones cacheadas. **Si estás en Databricks** has click en `Compute`, luego en `Spark UI` y despues click en `Storage`, deberias ver esto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f90caeca-c99b-45b3-b78e-0a84d1ae1398",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![](files/dataframes-api/images/1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dfe56e33-a738-48ea-8642-db16b2b32119",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Una diferencia fundamental a la hora de persistir un DataFrame en comparación con un RDD, es que como Spark SQL conoce el esquema de los datos en el DataFrame, puede organizarlos de forma columnar y aplicar compresión sobre éstos para minimizar el espacio necesario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea349fef-a888-4019-8001-bdaeba4e5a1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## DataFrames y Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5dd4b4e-28c5-448b-801a-a7cfe99b4a6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "En cualquier momento podemos pasar los datos de un DataFrame de PySpark a uno de Pandas para poder aprovechar su API.\n",
    "\n",
    "Si seguimos con el dataset de Yelp, vamos a preparar una consulta de nos devuelva la cantidad de votos recibidos y puntuación media de cada ciudad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7663e35b-16d9-44ee-9f26-4a660dd8d727",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- attributes: struct (nullable = true)\n |    |-- Accepts Credit Cards: boolean (nullable = true)\n |    |-- Alcohol: string (nullable = true)\n |    |-- Ambience: struct (nullable = true)\n |    |    |-- casual: boolean (nullable = true)\n |    |    |-- classy: boolean (nullable = true)\n |    |    |-- divey: boolean (nullable = true)\n |    |    |-- hipster: boolean (nullable = true)\n |    |    |-- intimate: boolean (nullable = true)\n |    |    |-- romantic: boolean (nullable = true)\n |    |    |-- touristy: boolean (nullable = true)\n |    |    |-- trendy: boolean (nullable = true)\n |    |    |-- upscale: boolean (nullable = true)\n |    |-- Attire: string (nullable = true)\n |    |-- Delivery: boolean (nullable = true)\n |    |-- Good For: struct (nullable = true)\n |    |    |-- breakfast: boolean (nullable = true)\n |    |    |-- brunch: boolean (nullable = true)\n |    |    |-- dessert: boolean (nullable = true)\n |    |    |-- dinner: boolean (nullable = true)\n |    |    |-- latenight: boolean (nullable = true)\n |    |    |-- lunch: boolean (nullable = true)\n |    |-- Good For Groups: boolean (nullable = true)\n |    |-- Good for Kids: boolean (nullable = true)\n |    |-- Has TV: boolean (nullable = true)\n |    |-- Noise Level: string (nullable = true)\n |    |-- Outdoor Seating: boolean (nullable = true)\n |    |-- Parking: struct (nullable = true)\n |    |    |-- garage: boolean (nullable = true)\n |    |    |-- lot: boolean (nullable = true)\n |    |    |-- street: boolean (nullable = true)\n |    |    |-- valet: boolean (nullable = true)\n |    |    |-- validated: boolean (nullable = true)\n |    |-- Price Range: long (nullable = true)\n |    |-- Take-out: boolean (nullable = true)\n |    |-- Takes Reservations: boolean (nullable = true)\n |    |-- Waiter Service: boolean (nullable = true)\n |    |-- Wheelchair Accessible: boolean (nullable = true)\n |    |-- Wi-Fi: string (nullable = true)\n |-- business_id: string (nullable = true)\n |-- categories: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- city: string (nullable = true)\n |-- full_address: string (nullable = true)\n |-- hours: struct (nullable = true)\n |    |-- Friday: struct (nullable = true)\n |    |    |-- close: string (nullable = true)\n |    |    |-- open: string (nullable = true)\n |    |-- Monday: struct (nullable = true)\n |    |    |-- close: string (nullable = true)\n |    |    |-- open: string (nullable = true)\n |    |-- Saturday: struct (nullable = true)\n |    |    |-- close: string (nullable = true)\n |    |    |-- open: string (nullable = true)\n |    |-- Sunday: struct (nullable = true)\n |    |    |-- close: string (nullable = true)\n |    |    |-- open: string (nullable = true)\n |    |-- Thursday: struct (nullable = true)\n |    |    |-- close: string (nullable = true)\n |    |    |-- open: string (nullable = true)\n |    |-- Tuesday: struct (nullable = true)\n |    |    |-- close: string (nullable = true)\n |    |    |-- open: string (nullable = true)\n |    |-- Wednesday: struct (nullable = true)\n |    |    |-- close: string (nullable = true)\n |    |    |-- open: string (nullable = true)\n |-- latitude: double (nullable = true)\n |-- longitude: double (nullable = true)\n |-- name: string (nullable = true)\n |-- neighborhoods: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- open: boolean (nullable = true)\n |-- review_count: long (nullable = true)\n |-- stars: double (nullable = true)\n |-- state: string (nullable = true)\n |-- type: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"s8a-dataframes-arrays\").getOrCreate()\n",
    "\n",
    "df = spark.read.option(\"inferSchema\", \"true\").option(\"multiline\",True).json(\"/FileStore/dataframes-api/dataset/yelp_academic_dataset_business.json\")\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d23471a7-bcda-4005-81ee-2991e29b61c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n|   city|\n+-------+\n|Phoenix|\n+-------+\n\n"
     ]
    }
   ],
   "source": [
    "df.select(\"city\").distinct().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21ac00d8-ccf4-48cf-9330-613003294185",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+\n|   city|votos|media|\n+-------+-----+-----+\n|Phoenix|    1|  4.0|\n+-------+-----+-----+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count, avg, round\n",
    "dfVotosCiudades = df.groupBy(\"city\").agg(count(\"city\").alias(\"votos\"), round(avg(\"stars\"), 3).alias(\"media\")).orderBy(\"votos\", ascending=False).limit(10)\n",
    "dfVotosCiudades.show()\n",
    "# +----------+-----+-----+\n",
    "# |      city|votos|media|\n",
    "# +----------+-----+-----+\n",
    "# |   Phoenix| 5492|3.658|\n",
    "# |Scottsdale| 2617|3.809|\n",
    "# |     Tempe| 1444| 3.64|\n",
    "# |      Mesa| 1348|3.644|\n",
    "# |  Chandler| 1178|3.677|\n",
    "# |  Glendale|  821|3.588|\n",
    "# |   Gilbert|  630|3.755|\n",
    "# |    Peoria|  385|3.614|\n",
    "# |  Surprise|  241|3.598|\n",
    "# |  Goodyear|  214|3.498|\n",
    "# +----------+-----+-----+\n",
    "# Esta salida se corresponde a la dataset completa de Kaggle en vez de nuestra muestra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d107cce3-8574-40f2-9077-d3d62c0b9c36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Nos traemos esos datos a Pandas mediante el método .`toPandas()`.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fd36b24-afa4-4d7e-a4ec-0608255e19c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdVC = dfVotosCiudades.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "da8d4250-9e17-4dd8-812e-a856a0e5f162",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "A partir de este momento pdVC es un DataFrame de Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22172bb0-73a6-4c92-be7f-27e306050ce2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>votos</th>\n",
       "      <th>media</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>city</th>\n      <th>votos</th>\n      <th>media</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Phoenix</td>\n      <td>1</td>\n      <td>4.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pdVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c0152bcf-3c61-4f05-840e-4b93ac61beda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Y con el DataFrame de Pandas, ya podemos generar gráficos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a8ece8b-20a4-4419-9284-a6bd5b56a733",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [\"pdVC\"], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n"
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "data:image/png;base64,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\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "image"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.ticklabel_format(useOffset=False, style=\"plain\")\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.barplot(x=\"votos\", y=\"city\", data=pdVC).set_title(\"Votos por Ciudad\")\n",
    "plt.xlabel(\"Votos emitidos\")\n",
    "plt.ylabel(\"Ciudades\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f9c07fbc-59dd-4fc9-91a3-aaec04c2c146",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Mas exactamente la salida para la dataset completa sería:  \n",
    "![](files/dataframes-api/images/5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7e683c1-3caa-4c6d-b66a-845baa967203",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "O por ejemplo, si queremos unir dos gráficos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b59431c8-20e2-4dae-b70d-7851714b8ca1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n"
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "data:image/png;base64,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\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "image"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.set_theme(style=\"white\")\n",
    "ax = sns.barplot(data = pdVC, y=\"votos\", x=\"city\")\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "sns.lineplot(data = pdVC['media'], marker='o', color='crimson', ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "513628db-1b01-44df-86ac-8eb0b1d51d2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Mas exactamente la salida para la dataset completa sería:  \n",
    "![](files/dataframes-api/images/6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa4a1bc1-d78c-4c29-b066-f8f027731416",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> **Out of Memory**  \n",
    "> Mucho cuidado al utilizar Pandas, ya que al convertir el DataFrame nos vamos a traer todos los datos al driver, perdiendo la distribución de los datos y pudiendo provocar un error de falta de memoria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8348636d-93ae-49bf-89c0-6c354b1d2d10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Así pues, hay que evitar a toda costa utilizar Pandas para tratar los datos, ya que perdemos toda la potencia de trabajo en clúster (Pandas sólo puede utilizar los recursos del nodo principal). Únicamente lo utilizaremos cuando vayamos a visualizar los datos mediante Matplotlib / Seaborn como requisito de estas librerías."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a8a51b3-9a43-40f9-a54a-14a76007804a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "> **Pandas y Koalas**  \n",
    "> Desde la versión 3.2 de Spark, la librería de [Koalas](https://koalas.readthedocs.io/en/latest/) se ha integrado en Spark, dando lugar a poder utilizar el API de Pandas directamente desde Spark, lo que facilita el aprendizaje de Spark para aquellos desarrolladores que ya dominan Pandas. Para ello, únicamente hemos de importar la librería:  \n",
    "`import pyspark.pandas as ps`  \n",
    "Y acceder a `ps` de la misma manera que usamos `pd` al trabajar con Pandas.  \n",
    "Un artículo muy interesante es [Run Pandas as Fast as Spark.](https://towardsdatascience.com/run-pandas-as-fast-as-spark-f5eefe780c45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "25687518-b30c-4d96-bd4e-95203f986539",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Actividades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "696e4235-c336-46e9-a353-6453454b8199",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "En las siguientes actividades vamos a realizar agregaciones mediante el uso del API de DataFrames de Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7168264-0d67-4d22-8082-765e3c414bbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. Sobre las películas de la sesión anterior `movies.tsv`:  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab482ff8-c98f-4f38-bef3-e2bcb6fe56c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- actor: string (nullable = true)\n |-- title: string (nullable = true)\n |-- year: string (nullable = true)\n\n+-----------------+-------------+----+\n|            actor|        title|year|\n+-----------------+-------------+----+\n|McClure, Marc (I)|Freaky Friday|2003|\n|McClure, Marc (I)| Coach Carter|2005|\n|McClure, Marc (I)|  Superman II|1980|\n|McClure, Marc (I)|    Apollo 13|1995|\n|McClure, Marc (I)|     Superman|1978|\n+-----------------+-------------+----+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Cargar el archivo sin cabeceras y con el separador de tabulador\n",
    "df = spark.read.option(\"sep\", \"\\t\").csv(\"/FileStore/dataframes-api/dataset/movies.tsv\")\n",
    "\n",
    "# Asignar nombres a las columnas\n",
    "df = df.withColumnRenamed(\"_c0\", \"actor\").withColumnRenamed(\"_c1\", \"title\").withColumnRenamed(\"_c2\", \"year\")\n",
    "\n",
    "# Mostrar el esquema y las primeras filas para verificar la carga\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14d12ef4-e106-44bb-881e-191a9df07a6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    " a. ¿Cuantas películas diferentes hay?  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "687ae84b-05d3-44d7-8bc5-18c0b908d16e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[101]: 1409"
     ]
    }
   ],
   "source": [
    "# Contar las películas distintas\n",
    "df.select(\"title\").distinct().count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e00fb18-7bf9-4902-a6d3-8df4e751f9ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    " b. ¿En cuantas películas ha trabajado Murphy, Eddie (I)?  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a8dc2bd-86df-4b93-b1f1-57a014ded9d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[102]: 21"
     ]
    }
   ],
   "source": [
    "# Filtrar las películas en las que aparece Eddie Murphy\n",
    "murphy_movies = df.filter(df[\"actor\"].like(\"%Murphy, Eddie (I)%\"))\n",
    "\n",
    "# Contar cuántas películas ha trabajado Eddie Murphy\n",
    "murphy_movies.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56241aec-0515-41dc-9765-2fb54b109322",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "c. ¿Cuáles son los actores que han aparecido en más de 30 películas?  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4c75414-2c58-4fab-91fb-84b2bc6b89ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------+\n|             actor|num_movies|\n+------------------+----------+\n|     Harnell, Jess|        31|\n|  Tatasciore, Fred|        38|\n|Jackson, Samuel L.|        32|\n|     Welker, Frank|        38|\n+------------------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "\n",
    "# Contamos las películas por actor\n",
    "actors_count = df.groupBy(\"actor\").agg(count(\"title\").alias(\"num_movies\"))\n",
    "\n",
    "# Filtrar actores que han aparecido en más de 30 películas\n",
    "actors_count.filter(actors_count[\"num_movies\"] > 30).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9c96fb4-7871-4a58-928f-72ca2057c0d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "d. ¿En que película anterior a 1980 aparecen al menos 25 intérpretes?  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "613955c5-5e16-417e-8fd6-319395d4bc52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+----+\n|title    |actor_count|year|\n+---------+-----------+----+\n|Star Wars|25         |1977|\n+---------+-----------+----+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split, collect_set, size\n",
    "\n",
    "# Paso 1: Dividir los actores por coma\n",
    "df_split = df.withColumn(\"actor_list\", split(df[\"actor\"], \",\"))\n",
    "\n",
    "# Paso 2: Agrupar por 'title' (película) y obtener los actores únicos para cada película\n",
    "df_grouped = df_split.groupBy(\"title\", \"year\").agg(collect_set(\"actor_list\").alias(\"actor_list\"))\n",
    "\n",
    "# Paso 3: Contar el número de actores únicos por película\n",
    "df_grouped = df_grouped.withColumn(\"actor_count\", size(df_grouped[\"actor_list\"]))\n",
    "\n",
    "# Paso 4: Filtrar las películas anteriores a 1980 y con al menos 25 actores\n",
    "df_filtered = df_grouped.filter((df_grouped[\"year\"] < 1980) & (df_grouped[\"actor_count\"] >= 25))\n",
    "\n",
    "# Paso 5: Mostrar el nombre de la película y el número de actores para las películas que cumplen la condición\n",
    "df_filtered.select(\"title\", \"actor_count\", \"year\").show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d3205bd-005e-4146-942b-2055eb38d88b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "e. Muestra la cantidad de películas producidas cada año (solo debe mostrar el año y la cantidad), ordenando el listado por la cantidad de forma descendente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1cb84015-b801-4345-9802-9a6b1a623421",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+\n|year|num_movies|\n+----+----------+\n|2006|      2078|\n|2004|      2005|\n|2007|      1986|\n|2005|      1960|\n|2011|      1926|\n|2008|      1892|\n|2009|      1890|\n|2010|      1843|\n|2002|      1834|\n|2001|      1687|\n|2003|      1652|\n|2000|      1639|\n|1997|      1584|\n|1999|      1401|\n|1998|      1372|\n|1996|       916|\n|2012|       601|\n|1995|       498|\n|1994|       358|\n|1992|       304|\n+----+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Agrupar por año y contar las películas producidas cada año\n",
    "movies_by_year = df.groupBy(\"year\").agg(count(\"title\").alias(\"num_movies\"))\n",
    "\n",
    "# Ordenar de forma descendente por la cantidad de películas\n",
    "movies_by_year.orderBy(\"num_movies\", ascending=False).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21223f0b-ce03-4254-8ef8-9b8f12460b69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "2.  Nos han enviado un nuevo archivo llamado [movie-ratings.tsv](https://tajamar365.sharepoint.com/:u:/s/3405-MasterIA2024-2025/ESyjlCu2YQdGpqcMWiFTCp0BNJZaVLAXMurp-xVf_aUwsA?e=MxM7Bb) que contiene las calificaciones de las películas.  \n",
    "  a. Crea un DataFrame que contenga los datos de ambos datasets.  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e4c451a-85cd-45cd-a878-ee5b42e53a6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------------------------+----+\n|actor            |title                      |year|\n+-----------------+---------------------------+----+\n|McClure, Marc (I)|Freaky Friday              |2003|\n|McClure, Marc (I)|Coach Carter               |2005|\n|McClure, Marc (I)|Superman II                |1980|\n|McClure, Marc (I)|Apollo 13                  |1995|\n|McClure, Marc (I)|Superman                   |1978|\n|McClure, Marc (I)|Back to the Future         |1985|\n|McClure, Marc (I)|Back to the Future Part III|1990|\n|Cooper, Chris (I)|Me, Myself & Irene         |2000|\n|Cooper, Chris (I)|October Sky                |1999|\n|Cooper, Chris (I)|Capote                     |2005|\n|Cooper, Chris (I)|The Bourne Supremacy       |2004|\n|Cooper, Chris (I)|The Patriot                |2000|\n|Cooper, Chris (I)|The Town                   |2010|\n|Cooper, Chris (I)|Seabiscuit                 |2003|\n|Cooper, Chris (I)|A Time to Kill             |1996|\n|Cooper, Chris (I)|Where the Wild Things Are  |2009|\n|Cooper, Chris (I)|The Muppets                |2011|\n|Cooper, Chris (I)|American Beauty            |1999|\n|Cooper, Chris (I)|Syriana                    |2005|\n|Cooper, Chris (I)|The Horse Whisperer        |1998|\n+-----------------+---------------------------+----+\nonly showing top 20 rows\n\n+-------+--------------------------+----+\n|rating |title                     |_c2 |\n+-------+--------------------------+----+\n|1.6339 |'Crocodile' Dundee II     |1988|\n|7.6177 |10                        |1979|\n|1.2864 |10 Things I Hate About You|1999|\n|0.3243 |10,000 BC                 |2008|\n|0.3376 |101 Dalmatians            |1996|\n|0.5218 |102 Dalmatians            |2000|\n|12.8205|1066                      |2012|\n|0.6829 |12                        |2007|\n|7.4061 |12 Rounds                 |2009|\n|2.3677 |127 Hours                 |2010|\n|1.3585 |13 Going on 30            |2004|\n|8.4034 |13 game sayawng           |2006|\n|0.59   |1408                      |2007|\n|4.4292 |15 Minutes                |2001|\n|2.2118 |16 Blocks                 |2006|\n|1.0491 |17 Again                  |2009|\n|3.9265 |1941                      |1979|\n|10.4757|2 Days in the Valley      |1996|\n|0.4    |2 Fast 2 Furious          |2003|\n|11.1111|2 Guns                    |2013|\n+-------+--------------------------+----+\nonly showing top 20 rows\n\n+---------------------------+-----------------+----+------+----+\n|title                      |actor            |year|rating|_c2 |\n+---------------------------+-----------------+----+------+----+\n|Freaky Friday              |McClure, Marc (I)|2003|0.3847|2003|\n|Coach Carter               |McClure, Marc (I)|2005|0.9858|2005|\n|Superman II                |McClure, Marc (I)|1980|0.8739|1980|\n|Apollo 13                  |McClure, Marc (I)|1995|1.0267|1995|\n|Superman                   |McClure, Marc (I)|1978|1.1982|1978|\n|Back to the Future         |McClure, Marc (I)|1985|0.1904|1985|\n|Back to the Future Part III|McClure, Marc (I)|1990|1.678 |1990|\n|Me, Myself & Irene         |Cooper, Chris (I)|2000|0.5611|2000|\n|October Sky                |Cooper, Chris (I)|1999|1.603 |1999|\n|Capote                     |Cooper, Chris (I)|2005|1.9389|2005|\n|The Bourne Supremacy       |Cooper, Chris (I)|2004|0.3015|2004|\n|The Patriot                |Cooper, Chris (I)|2000|0.5363|2000|\n|The Town                   |Cooper, Chris (I)|2010|0.7352|2010|\n|Seabiscuit                 |Cooper, Chris (I)|2003|0.4242|2003|\n|A Time to Kill             |Cooper, Chris (I)|1996|0.4878|1996|\n|Where the Wild Things Are  |Cooper, Chris (I)|2009|0.7966|2009|\n|The Muppets                |Cooper, Chris (I)|2011|0.668 |2011|\n|American Beauty            |Cooper, Chris (I)|1999|0.2136|1999|\n|Syriana                    |Cooper, Chris (I)|2005|0.9458|2005|\n|The Horse Whisperer        |Cooper, Chris (I)|1998|0.5985|1998|\n+---------------------------+-----------------+----+------+----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Cargar movies.tsv sin cabeceras\n",
    "movies_df = spark.read.option(\"sep\", \"\\t\").csv(\"/FileStore/dataframes-api/dataset/movies.tsv\")\n",
    "\n",
    "# Asignar nombres a las columnas\n",
    "movies_df = movies_df.withColumnRenamed(\"_c0\", \"actor\").withColumnRenamed(\"_c1\", \"title\").withColumnRenamed(\"_c2\", \"year\")\n",
    "\n",
    "# Convertir las columnas necesarias a tipo adecuado\n",
    "movies_df = movies_df.withColumn(\"year\", movies_df[\"year\"].cast(\"int\"))\n",
    "\n",
    "# Verificar los datos\n",
    "movies_df.show(truncate=False)\n",
    "\n",
    "\n",
    "# Cargar movie-ratings.tsv sin cabeceras\n",
    "ratings_df = spark.read.option(\"sep\", \"\\t\").csv(\"/FileStore/dataframes-api/dataset/movie_ratings.tsv\")\n",
    "\n",
    "# Asignar nombres a las columnas\n",
    "ratings_df = ratings_df.withColumnRenamed(\"_c0\", \"rating\").withColumnRenamed(\"_c1\", \"title\")\n",
    "\n",
    "# Convertir la columna de rating a tipo adecuado (float)\n",
    "ratings_df = ratings_df.withColumn(\"rating\", ratings_df[\"rating\"].cast(\"float\"))\n",
    "\n",
    "# Verificar los datos\n",
    "ratings_df.show(truncate=False)\n",
    "\n",
    "# Unir ambos DataFrames por la columna 'title'\n",
    "movies_ratings_df = movies_df.join(ratings_df, on=\"title\", how=\"inner\")\n",
    "\n",
    "# Verificar la unión\n",
    "movies_ratings_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b2fcdf6e-84dd-4151-a271-aa12cccfe314",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    " b. Muestra para cada año, la película con mayor puntuación (año, título de la película, puntuación)  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3966ee86-74e3-4737-9483-f8ca68590c07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------------------+----------+\n|year|title                         |max_rating|\n+----+------------------------------+----------+\n|1961|One Hundred and One Dalmatians|0.6726    |\n|1967|The Jungle Book               |10.6763   |\n|1972|The Godfather                 |0.5099    |\n|1973|The Exorcist                  |0.6581    |\n|1975|Jaws                          |0.701     |\n|1977|Saturday Night Fever          |1.2184    |\n|1978|Jaws 2                        |1.9793    |\n|1979|Apocalypse Now                |1.9906    |\n|1980|Superman II                   |0.8739    |\n|1981|Absence of Malice             |2.1052    |\n|1982|First Blood                   |1.2501    |\n|1983|Yentl                         |1.4011    |\n|1984|The Terminator                |2.061     |\n|1985|Kiss of the Spider Woman      |2.1       |\n|1986|An American Tail              |14.2122   |\n|1987|RoboCop                       |10.0      |\n|1988|Child's Play                  |1.7632    |\n|1989|Lethal Weapon 2               |1.7087    |\n|1990|Presumed Innocent             |2.0055    |\n|1991|JFK                           |2.0171    |\n+----+------------------------------+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import max, col\n",
    "\n",
    "# Paso 1: Agrupar por año y obtener la puntuación máxima por año\n",
    "best_movies_per_year = movies_ratings_df.groupBy(\"year\").agg(\n",
    "    max(\"rating\").alias(\"max_rating\")\n",
    ")\n",
    "\n",
    "# Renombrar las columnas de los DataFrames para evitar la ambigüedad\n",
    "best_movies_per_year = best_movies_per_year.withColumnRenamed(\"year\", \"year_best\")\n",
    "\n",
    "# Eliminar duplicados\n",
    "movies_ratings_no_duplicates = movies_ratings_df.dropDuplicates([\"year\", \"title\", \"rating\"])\n",
    "\n",
    "# Paso 2: Unir con el DataFrame original para obtener el título de la película con la puntuación máxima\n",
    "best_movies_with_title = best_movies_per_year.join(\n",
    "    movies_ratings_no_duplicates,\n",
    "    (movies_ratings_no_duplicates[\"year\"] == best_movies_per_year[\"year_best\"]) & \n",
    "    (movies_ratings_no_duplicates[\"rating\"] == best_movies_per_year[\"max_rating\"]),\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# Paso 3: Seleccionar las columnas deseadas: año, título y puntuación máxima\n",
    "best_movies_per_year_with_title = best_movies_with_title.select(\n",
    "    col(\"year_best\").alias(\"year\"), \n",
    "    \"title\", \n",
    "    \"max_rating\"\n",
    ").distinct()  # Asegurarse de que las filas sean únicas\n",
    "\n",
    "# Paso 4: Ordenar por año (puedes usar 'desc' para ordenarlo en orden descendente)\n",
    "best_movies_per_year_with_title = best_movies_per_year_with_title.orderBy(\"year\")\n",
    "\n",
    "# Mostrar el resultado\n",
    "best_movies_per_year_with_title.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5279a957-fe40-4c50-83dc-274b91eb8605",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "c. Sobre los datos anteriores, obtén también una lista con los nombres de los intérpretes.  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4f65338-be3c-4abe-9310-9162476feebf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------------------+----------+----------------------+\n|year|title                         |max_rating|actors                |\n+----+------------------------------+----------+----------------------+\n|1961|One Hundred and One Dalmatians|0.6726    |[Wickes, Mary]        |\n|1967|The Jungle Book               |10.6763   |[Howard, Clint]       |\n|1972|The Godfather                 |0.5099    |[Brando, Marlon]      |\n|1973|The Exorcist                  |0.6581    |[Burstyn, Ellen]      |\n|1975|Jaws                          |0.701     |[Grossman, Ted (I)]   |\n|1977|Saturday Night Fever          |1.2184    |[Dillon, Denny]       |\n|1978|Jaws 2                        |1.9793    |[Scheider, Roy]       |\n|1979|Apocalypse Now                |1.9906    |[Brando, Marlon]      |\n|1980|Superman II                   |0.8739    |[McClure, Marc (I)]   |\n|1981|Absence of Malice             |2.1052    |[Balaban, Bob]        |\n|1982|First Blood                   |1.2501    |[Tamburro, Charles A.]|\n|1983|Yentl                         |1.4011    |[Streisand, Barbra]   |\n|1984|The Terminator                |2.061     |[Miller, Dick (I)]    |\n|1985|Kiss of the Spider Woman      |2.1       |[Hurt, William]       |\n|1986|An American Tail              |14.2122   |[Finnegan, John (I)]  |\n|1987|RoboCop                       |10.0      |[Machado, Mario]      |\n|1988|Child's Play                  |1.7632    |[Gale, Ed]            |\n|1989|Lethal Weapon 2               |1.7087    |[Wilson, Norman D.]   |\n|1990|Presumed Innocent             |2.0055    |[Dennehy, Brian]      |\n|1991|JFK                           |2.0171    |[Herthum, Harold G.]  |\n+----+------------------------------+----------+----------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Paso 1: Agrupar por año y obtener la puntuación máxima por año\n",
    "best_movies_per_year = movies_ratings_df.groupBy(\"year\").agg(\n",
    "    F.max(\"rating\").alias(\"max_rating\")\n",
    ")\n",
    "\n",
    "# Renombrar las columnas de los DataFrames para evitar la ambigüedad\n",
    "best_movies_per_year = best_movies_per_year.withColumnRenamed(\"year\", \"year_best\")\n",
    "\n",
    "# Eliminar duplicados en el DataFrame original\n",
    "movies_ratings_no_duplicates = movies_ratings_df.dropDuplicates([\"year\", \"title\", \"rating\"])\n",
    "\n",
    "# Paso 2: Unir con el DataFrame original para obtener el título de la película con la puntuación máxima\n",
    "best_movies_with_title = best_movies_per_year.join(\n",
    "    movies_ratings_no_duplicates,\n",
    "    (movies_ratings_no_duplicates[\"year\"] == best_movies_per_year[\"year_best\"]) & \n",
    "    (movies_ratings_no_duplicates[\"rating\"] == best_movies_per_year[\"max_rating\"]),\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "# Paso 3: Crear una lista única de actores por película\n",
    "best_movies_with_actors = best_movies_with_title.groupBy(\"year\", \"title\", \"max_rating\").agg(\n",
    "    F.collect_set(\"actor\").alias(\"actors\")  # Usamos collect_set para eliminar duplicados\n",
    ")\n",
    "\n",
    "# Paso 4: Ordenar por año (puedes usar 'desc' para ordenarlo en orden descendente)\n",
    "best_movies_with_actors = best_movies_with_actors.orderBy(\"year\")\n",
    "\n",
    "# Mostrar el resultado final\n",
    "best_movies_with_actors.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9952ed0b-eee1-41d4-b0b2-6c1bb09703be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "d. Averigua las tres parejas de intérpretes han trabajado juntos en más ocasiones. La salida debe tener tres columnas: `interprete1`, `interprete2` y `cantidad`. (necesitas utilizar un *self-join*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9127b326-1a96-48dd-b490-6554a373b59c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+--------+\n|interprete1     |interprete2     |cantidad|\n+----------------+----------------+--------+\n|Lynn, Sherry (I)|McGowan, Mickie |23      |\n|Bergen, Bob (I) |McGowan, Mickie |19      |\n|Bergen, Bob (I) |Lynn, Sherry (I)|19      |\n+----------------+----------------+--------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Paso 1: Crear un self-join\n",
    "# Hacemos un self-join de la tabla de películas, asegurándonos de que los actores no sean los mismos.\n",
    "self_join_df = movies_ratings_df.alias('df1').join(\n",
    "    movies_ratings_df.alias('df2'),\n",
    "    (F.col('df1.title') == F.col('df2.title')) & \n",
    "    (F.col('df1.actor') < F.col('df2.actor')),  # Esto evita duplicados, es decir, no comparar 'actor1' con 'actor2' y viceversa\n",
    "    'inner'\n",
    ")\n",
    "\n",
    "# Paso 2: Crear una columna que contenga las parejas de actores\n",
    "self_join_df = self_join_df.withColumn(\n",
    "    \"actor_pair\", \n",
    "    F.array(F.col('df1.actor'), F.col('df2.actor'))\n",
    ")\n",
    "\n",
    "# Paso 3: Agrupar por la pareja de actores y contar cuántas veces aparecen juntos\n",
    "actor_pairs_count = self_join_df.groupBy(\"actor_pair\").agg(\n",
    "    F.count(\"*\").alias(\"cantidad\")\n",
    ")\n",
    "\n",
    "# Paso 4: Desempaquetar la columna 'actor_pair' en dos columnas: 'interprete1' y 'interprete2'\n",
    "actor_pairs_count = actor_pairs_count.withColumn(\n",
    "    \"interprete1\", F.col(\"actor_pair\").getItem(0)\n",
    ").withColumn(\n",
    "    \"interprete2\", F.col(\"actor_pair\").getItem(1)\n",
    ")\n",
    "\n",
    "# Paso 5: Seleccionar las columnas deseadas y ordenar por cantidad en orden descendente\n",
    "actor_pairs_count = actor_pairs_count.select(\"interprete1\", \"interprete2\", \"cantidad\").orderBy(\"cantidad\", ascending=False)\n",
    "\n",
    "# Paso 6: Mostrar las tres parejas más frecuentes\n",
    "actor_pairs_count.show(3, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "69714e66-e682-4ae8-aa6b-2342ee99752b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Las siguientes dos actividades se plantean como un proyecto a realizar en clase:  \n",
    "3. Hemos recibido un dataset con las ventas de 2019 de una tienda americana de productos de tecnología, mediante un conjunto de ficheros en formato CSV comprimidos en [salesdata.zip](https://tajamar365.sharepoint.com/:u:/s/3405-MasterIA2024-2025/EVv159rps6hJqglAU4Afs4MB-xJI0Vkp-d86wBfBod1JGg?e=0R9Qj4).   \n",
    "  a. Una vez descomprimidos los datos, crea un DataFrame con todos los datos, infiriendo el esquema.  \n",
    "  b. Vuelve a realizar la lectura de los datos pero con el siguiente esquema:  \n",
    "  ```<python>\n",
    "  from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "esquema = StructType([\n",
    "    StructField(\"Order ID\", IntegerType(), False),\n",
    "    StructField(\"Product\", StringType(), False),\n",
    "    StructField(\"Quantity Ordered\", IntegerType(), True),\n",
    "    StructField(\"Price Each\", DoubleType(), False),\n",
    "    StructField(\"Order Date\", StringType(), False),\n",
    "    StructField(\"Purchase Address\", StringType(), False)\n",
    "])\n",
    "  ```\n",
    "\n",
    "  c. Tras la lectura, vamos a realizar la limpieza de datos. El primer paso será renombrar la columnas para eliminar los espacios en blanco.  \n",
    "  d. Elimina las filas que contengan algún campo nulo.  \n",
    "  e. Comprueba si las cabeceras de los archivos aparecen como datos del dataset (por ejemplo, un producto cuyo nombre sea Product). Si fuera el caso, elimina dichas filas.  \n",
    "  f. A partir del campo dirección, crea dos nuevas columnas para almacenar la ciudad (`City`) y el estado (`State`). Por ejemplo, para la dirección `136 Church St, New York City, NY 10001`, la ciudad es `New York City` y el estado es `NY`.  \n",
    "  g. Modifica el campo con la fecha del pedido para que su formato sea *timestamp*.  \n",
    "  h. Sobre el campo anterior, crea dos nuevas columnas, con el mes (`Month`) y el año (`Year`) del pedido.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e814647a-7513-499f-8e84-137bca7852dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "4. Una vez realizada la transformación de los datos, vamos a realizar su carga y extraer información, utilizando Spark SQL siempre que sea posible:  \n",
    "  a. Almacena los datos en formato *Parquet* en la carpeta `salesoutput` particionando los datos por año y mes. Tras ejecutar esta operación, comprueba en disco la estructura de archivos creada.  \n",
    "  b. Sobre los datos almacenados, realiza una nueva lectura pero solo leyendo los datos de 2019 los cuales deberían estar almacenados en `./salesdataoutput/Year=2019`  \n",
    "  c. Averigua cual ha sido el mes que ha recaudado más. Para ello, deberás multiplicar el precio por la cantidad de unidades, y posteriormente, realizar alguna agregación. Sobre el resultado, crea un gráfico (usando matplotlib y seaborn) similar al siguiente:  \n",
    "  ![](https://community.cloud.databricks.com/files/Notebook_3/2.png)  \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b05a7cc3-7efc-42f0-b8a9-006c3f63e641",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "  d. Obtén un gráfico con las 10 ciudades que más unidades han vendido.  \n",
    "  ![](https://community.cloud.databricks.com/files/Notebook_3/3.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d66a5f56-9c48-48ef-8e26-08a1d3af1d7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "e. Cantidad de pedidos por Horas en las que se ha realizado un pedido que contenía al menos dos productos:  \n",
    "![](https://community.cloud.databricks.com/files/Notebook_3/4.png) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e4e315b8-41cc-4b5c-a22f-963696f33a2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "f. Listado con los productos del estado de NY que se han comprado a la vez, obteniendo un resultado similar a: \n",
    "``` \n",
    "+------------------------------------------------------------+-----+\n",
    "|Productos                                                   |count|\n",
    "+------------------------------------------------------------+-----+\n",
    "|[iPhone, Lightning Charging Cable]                          |126  |\n",
    "|[Google Phone, USB-C Charging Cable]                        |124  |\n",
    "|[Google Phone, Wired Headphones]                            |52   |\n",
    "...\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "notebook",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
